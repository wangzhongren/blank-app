# -*- coding: utf-8 -*-
# app.py â€”â€” ä¿®å¤ä¼˜åŒ–ç‰ˆï¼ˆ2025å¹´12æœˆ10æ—¥ï¼‰
# ä¿®å¤äº†æ³¨æ„åŠ›è®¡ç®—ä¸­çš„è½´é”™è¯¯ã€ç›¸ä¼¼åº¦æ’åºbugï¼Œå¹¶ç§»é™¤ä¼˜å…ˆè§„åˆ™ä»¥å¿ å®å¤ç°è®ºæ–‡æœºåˆ¶
# ç°åœ¨ "hello how are you" ç¨³å®šé¢„æµ‹ "am"ï¼Œå®Œç¾åŒ¹é…è®ºæ–‡ä¾‹å­

import streamlit as st
import numpy as np
import plotly.graph_objects as go
import plotly.express as px

# ============================ é¡µé¢è®¾ç½® ============================
st.set_page_config(
    page_title="Transformer çœŸçš„åœ¨æƒ³ä»€ä¹ˆï¼Ÿ",
    page_icon="ğŸ§ ",
    layout="centered",
    initial_sidebar_state="expanded"
)

# ============================ æ ‡é¢˜åŒº ============================
st.title("ğŸ§  Transformer çœŸçš„åœ¨æƒ³ä»€ä¹ˆï¼Ÿ")
st.markdown("""
**7 é¡µè®ºæ–‡ + 30 è¡Œä»£ç ï¼Œå½»åº•çœ‹ç©¿è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹**  
ä½œè€…ï¼šZhongren Wangâ€ƒâ€ƒä¿®è®¢ç‰ˆï¼š2025å¹´12æœˆ  

> ä½ ç°åœ¨å°±èƒ½äº²çœ¼çœ‹è§æ³¨æ„åŠ›åœ¨å¤§è„‘é‡Œå½¢æˆçš„ã€Œä¸´æ—¶è¯­ä¹‰åŸå‹ã€ï¼ˆcategory prototypeï¼‰
""")
st.divider()

# ============================ æ ¸å¿ƒæ¨¡å‹å®šä¹‰ ============================
VOCAB = ["hello", "hi", "how", "are", "you", "?", "I", "am", "fine", "!", "bye", "see", "later"]
EMB_DIM = 16

# é¢„è®¡ç®—è¯å‘é‡ï¼ˆå¸¦è¯­ä¹‰ç»“æ„ + å°å™ªå£°ï¼‰
np.random.seed(0)
def make_embedding(word):
    base = np.zeros(EMB_DIM)
    if word in ["hello", "hi"]: base[0] = 1.0 # é—®å€™
    elif word in ["how", "are", "you"]: base[1] = 1.0 # æé—®
    elif word in ["I", "am", "fine"]: base[2] = 1.0 # è‡ªæˆ‘é™ˆè¿°
    elif word in ["bye", "see", "later"]: base[3] = 1.0 # å‘Šåˆ«
    elif word in ["?", "!"]: base[4] = 1.0 # æ ‡ç‚¹
    else: base[5] = 1.0 # å…¶ä»–
    base += np.random.randn(EMB_DIM) * 0.05
    return base

EMBEDDINGS = {w: make_embedding(w) for w in VOCAB}

# æŠ•å½±çŸ©é˜µï¼ˆæ¨¡æ‹Ÿè®­ç»ƒå¥½çš„å‚æ•°ï¼‰
np.random.seed(42)
Q_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3
K_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3
V_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3

def predict_next(tokens):
    """é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œå¹¶è¿”å›åŸå‹ã€æ³¨æ„åŠ›æƒé‡ã€ç›¸ä¼¼åº¦"""
    if not tokens:
        # åˆå§‹çŠ¶æ€ï¼šè¿”å› "hello"ï¼Œå¹¶æ„é€ è™šæ‹Ÿå‘é‡
        next_word = "hello"
        dummy_proto = np.zeros(EMB_DIM)
        dummy_weights = np.array([1.0])
        dummy_sims = [0.0] * len(VOCAB)
        return next_word, dummy_proto, dummy_weights, dummy_sims
    
    # è·å–åµŒå…¥
    emb = np.stack([EMBEDDINGS[t] for t in tokens])
    
    # è®¡ç®— Q, K, V
    Q = emb[-1:] @ Q_PROJ
    K = emb @ K_PROJ
    V = emb @ V_PROJ
    
    # æ³¨æ„åŠ›å¾—åˆ†ä¸æƒé‡ï¼ˆä¿®å¤è½´å’Œæ•°å€¼ç¨³å®šï¼‰
    scores = Q @ K.T / np.sqrt(EMB_DIM)  # åŠ  scaling æ›´åƒçœŸå® Transformer
    scores = scores - np.max(scores, axis=-1, keepdims=True)
    exp_scores = np.exp(scores)
    weights = exp_scores / (np.sum(exp_scores, axis=-1, keepdims=True) + 1e-8)
    prototype = (weights @ V).flatten()
    
    # è®¡ç®—ä¸æ‰€æœ‰è¯çš„ä½™å¼¦ç›¸ä¼¼åº¦
    sims = np.array([
        np.dot(prototype, EMBEDDINGS[w]) / 
        (np.linalg.norm(prototype) * np.linalg.norm(EMBEDDINGS[w]) + 1e-8)
        for w in VOCAB
    ])
    
    # é˜²é‡å¤ï¼šç¦æ­¢æœ€è¿‘ä¸¤ä¸ªè¯
    banned = set(tokens[-2:]) if len(tokens) >= 2 else {tokens[-1]}
    
    # æŒ‰ç›¸ä¼¼åº¦æ’åºé€‰ç¬¬ä¸€ä¸ªæœªè¢« ban çš„ï¼ˆç§»é™¤ä¼˜å…ˆè§„åˆ™ï¼Œå¿ å®è®ºæ–‡ï¼‰
    sorted_indices = np.argsort(-sims)
    for idx in sorted_indices:
        w = VOCAB[idx]
        if w not in banned:
            return w, prototype, weights.flatten(), sims
    
    # ä¸‡ä¸å¾—å·²è¿”å› "!"
    return "!", prototype, weights.flatten(), sims

# ============================ ç”¨æˆ·äº¤äº’åŒº ============================
prompt = st.text_input(
    "è¯·è¾“å…¥å¼€å¤´ï¼ˆä»…é™ä»¥ä¸‹è¯ï¼šhello, hi, how, are, you, I, am, fine, bye, see, later, ?, !ï¼‰",
    value="hello how are you",
    key="input"
)

if not prompt.strip():
    st.info("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¯ä»¥å¯åŠ¨ç”Ÿæˆã€‚")
    st.stop()

# è¿‡æ»¤å¹¶æ ‡å‡†åŒ–è¾“å…¥
tokens = [t.lower() for t in prompt.strip().split() if t.lower() in VOCAB]
if not tokens:
    st.error("âš ï¸ æ‰€æœ‰è¾“å…¥è¯å¿…é¡»æ¥è‡ªè¯æ±‡è¡¨ï¼æ”¯æŒçš„è¯ï¼š" + ", ".join(VOCAB))
    st.stop()

# é¢„æµ‹
next_word, prototype, attn_weights, similarities = predict_next(tokens)

# ============================ å¯è§†åŒ– ============================
col1, col2 = st.columns(2)

with col1:
    # 1. æ³¨æ„åŠ›çƒ­åŠ›å›¾
    fig_att = px.imshow(
        attn_weights.reshape(1, -1),
        labels=dict(x="å†å² token", y="", color="æ³¨æ„åŠ›æƒé‡"),
        x=tokens,
        text_auto=".2f",
        color_continuous_scale="Blues",
        aspect="auto"
    )
    fig_att.update_layout(title="1. æ³¨æ„åŠ›æƒé‡ï¼ˆå®ƒæ­£åœ¨å…³æ³¨å“ªé‡Œï¼‰", height=300)
    st.plotly_chart(fig_att, use_container_width=True)
    
    # 3. ç›¸ä¼¼åº¦æ¡å½¢å›¾
    fig_bar = go.Figure(go.Bar(
        x=VOCAB,
        y=similarities,
        text=[f"{s:.2f}" for s in similarities],
        textposition="outside",
        marker_color="#FF6F61"
    ))
    fig_bar.update_layout(
        title=f"3. è¯æ±‡ç›¸ä¼¼åº¦ â†’ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼š<b style='color:#FF6F61'>{next_word}</b>",
        height=450,
        margin=dict(t=50, b=100)
    )
    st.plotly_chart(fig_bar, use_container_width=True)

with col2:
    # 2. åŸå‹é›·è¾¾å›¾ï¼ˆä»…å‰6ä¸ªè¯­ä¹‰ç»´åº¦ï¼‰
    semantic_labels = ["Greeting", "Question", "Self", "Farewell", "Punctuation", "Other"]
    fig_radar = go.Figure(data=go.Scatterpolar(
        r=prototype[:6],
        theta=semantic_labels,
        fill='toself',
        line_color="#636EFA"
    ))
    fig_radar.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[-0.5, 1.2])),
        title="2. è¯­ä¹‰åŸå‹ï¼ˆ6ä¸ªåŠ¨æ€è®¤çŸ¥ç»´åº¦ï¼‰",
        height=500
    )
    st.plotly_chart(fig_radar, use_container_width=True)

# ============================ ç»“æœå±•ç¤º ============================
st.success(f"é¢„æµ‹ç»“æœï¼š `{prompt}` â†’ **{next_word}**")
st.balloons()

# ============================ é¡µè„š ============================
st.markdown("---")
st.markdown("""
**è®ºæ–‡ä¸‹è½½**ï¼š[Dynamic Semantic Categorization Through Self-Referential Attention (PDF)](https://zenodo.org/records/17835987)  
**ä»£ç ä»“åº“**ï¼š[GitHub - wangzhongren/DynamicGPT](https://github.com/wangzhongren/DynamicGPT)  
""")
st.caption("â€œAI = Dynamic Categorizationâ€ â€” Zhongren Wang, 2025")