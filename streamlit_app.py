# -*- coding: utf-8 -*-
# app.py â€”â€” å¸¦ç§å­è°ƒèŠ‚çš„åŠ¨æ€è¯­ä¹‰åŸå‹å¯è§†åŒ–å™¨ï¼ˆ2025å¹´12æœˆ10æ—¥ï¼‰
# åŸºäº Wang (2025): "AI = Dynamic Categorization"
# æ”¯æŒå®æ—¶è°ƒæ•´ QKV æŠ•å½±ç§å­ï¼Œè§‚å¯Ÿ Transformer å¦‚ä½•åŠ¨æ€æ„å»ºè¯­ä¹‰åŸå‹

import streamlit as st
import numpy as np
import plotly.graph_objects as go
import plotly.express as px

# ============================ é¡µé¢è®¾ç½® ============================
st.set_page_config(
    page_title="Transformer çœŸçš„åœ¨æƒ³ä»€ä¹ˆï¼Ÿ",
    page_icon="ğŸ§ ",
    layout="centered",
    initial_sidebar_state="expanded"
)

# ============================ ä¾§è¾¹æ ï¼šQKV ç§å­æ§åˆ¶ ============================
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹å‚æ•°")
    seed_proj = st.slider(
        "QKV æŠ•å½±ç§å­ (seed)",
        min_value=0,
        max_value=100,
        value=1,  # è®ºæ–‡æ¨èå€¼
        help="æ”¹å˜æ­¤å€¼ä¼šé‡æ–°ç”Ÿæˆ Q/K/V æŠ•å½±çŸ©é˜µï¼Œå½±å“æ³¨æ„åŠ›è¡Œä¸º"
    )
    st.info(f"å½“å‰ seed = {seed_proj}")
    st.markdown("""
    - **seed=1**ï¼šé€šå¸¸ç”Ÿæˆåˆç†å¯¹è¯ï¼ˆå¦‚ `you â†’ ?`ï¼‰  
    - **seed=42**ï¼šå¯èƒ½ç”Ÿæˆâ€œä¹±åºâ€ï¼ˆå¦‚ `you â†’ am`ï¼‰  
    - å°è¯•ä¸åŒå€¼ï¼Œè§‚å¯ŸåŸå‹å’Œé¢„æµ‹å¦‚ä½•å˜åŒ–ï¼
    """)

# ============================ æ ‡é¢˜åŒº ============================
st.title("ğŸ§  Transformer çœŸçš„åœ¨æƒ³ä»€ä¹ˆï¼Ÿ")
st.markdown("""
**7 é¡µè®ºæ–‡ + 30 è¡Œä»£ç ï¼Œå½»åº•çœ‹ç©¿è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹**  
ä½œè€…ï¼šZhongren Wangâ€ƒâ€ƒä¿®è®¢ç‰ˆï¼š2025å¹´12æœˆ  

> ä½ ç°åœ¨å°±èƒ½äº²çœ¼çœ‹è§æ³¨æ„åŠ›åœ¨å¤§è„‘é‡Œå½¢æˆçš„ã€Œä¸´æ—¶è¯­ä¹‰åŸå‹ã€ï¼ˆcategory prototypeï¼‰
""")
st.divider()

# ============================ æ ¸å¿ƒæ¨¡å‹å®šä¹‰ ============================
VOCAB = ["hello", "hi", "how", "are", "you", "?", "I", "am", "fine", "!", "bye", "see", "later"]
EMB_DIM = 16

# å›ºå®šè¯åµŒå…¥ï¼ˆseed=0 ä¿è¯è·¨è¿è¡Œä¸€è‡´æ€§ï¼‰
np.random.seed(0)
def make_embedding(word):
    base = np.zeros(EMB_DIM)
    if word in ["hello", "hi"]: base[0] = 1.0  # é—®å€™
    elif word in ["how", "are", "you"]: base[1] = 1.0  # æé—®
    elif word in ["I", "am", "fine"]: base[2] = 1.0  # è‡ªæˆ‘é™ˆè¿°
    elif word in ["bye", "see", "later"]: base[3] = 1.0  # å‘Šåˆ«
    elif word in ["?", "!"]: base[4] = 1.0  # æ ‡ç‚¹
    else: base[5] = 1.0  # å…¶ä»–
    base += np.random.randn(EMB_DIM) * 0.05  # å°å™ªå£°
    return base

EMBEDDINGS = {w: make_embedding(w) for w in VOCAB}

# ä½¿ç”¨ä¾§è¾¹æ  seed ç”Ÿæˆ QKV æŠ•å½±çŸ©é˜µ
np.random.seed(seed_proj)
Q_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3
K_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3
V_PROJ = np.random.randn(EMB_DIM, EMB_DIM) * 0.3

def predict_next(tokens):
    """é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œå¹¶è¿”å›åŸå‹ã€æ³¨æ„åŠ›æƒé‡ã€ç›¸ä¼¼åº¦"""
    if not tokens:
        # åˆå§‹çŠ¶æ€
        next_word = "hello"
        dummy_proto = np.zeros(EMB_DIM)
        dummy_weights = np.array([1.0])
        dummy_sims = [0.0] * len(VOCAB)
        return next_word, dummy_proto, dummy_weights, dummy_sims
    
    # è·å–åµŒå…¥
    emb = np.stack([EMBEDDINGS[t] for t in tokens])
    
    # QKV æŠ•å½±
    Q = emb[-1:] @ Q_PROJ
    K = emb @ K_PROJ
    V = emb @ V_PROJ
    
    # æ³¨æ„åŠ›è®¡ç®—ï¼ˆå¸¦ç¼©æ”¾å’Œæ•°å€¼ç¨³å®šï¼‰
    scores = Q @ K.T / np.sqrt(EMB_DIM)
    scores = scores - np.max(scores, axis=-1, keepdims=True)
    exp_scores = np.exp(scores)
    weights = exp_scores / (np.sum(exp_scores, axis=-1, keepdims=True) + 1e-8)
    prototype = (weights @ V).flatten()
    
    # ä½™å¼¦ç›¸ä¼¼åº¦
    sims = np.array([
        np.dot(prototype, EMBEDDINGS[w]) /
        (np.linalg.norm(prototype) * np.linalg.norm(EMBEDDINGS[w]) + 1e-8)
        for w in VOCAB
    ])
    
    # é˜²é‡å¤ï¼šç¦æ­¢æœ€è¿‘ä¸¤ä¸ªè¯
    banned = set(tokens[-2:]) if len(tokens) >= 2 else {tokens[-1]}
    
    # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œé€‰ç¬¬ä¸€ä¸ªæœªè¢« ban çš„
    sorted_indices = np.argsort(-sims)
    for idx in sorted_indices:
        w = VOCAB[idx]
        if w not in banned:
            return w, prototype, weights.flatten(), sims
    
    return "!", prototype, weights.flatten(), sims

# ============================ ç”¨æˆ·äº¤äº’åŒº ============================
prompt = st.text_input(
    "è¯·è¾“å…¥å¼€å¤´ï¼ˆä»…é™ä»¥ä¸‹è¯ï¼šhello, hi, how, are, you, I, am, fine, bye, see, later, ?, !ï¼‰",
    value="hello how are you",
    key="input"
)

if not prompt.strip():
    st.info("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¯ä»¥å¯åŠ¨ç”Ÿæˆã€‚")
    st.stop()

# è¿‡æ»¤è¾“å…¥
tokens = [t.lower() for t in prompt.strip().split() if t.lower() in VOCAB]
if not tokens:
    st.error("âš ï¸ æ‰€æœ‰è¾“å…¥è¯å¿…é¡»æ¥è‡ªè¯æ±‡è¡¨ï¼æ”¯æŒçš„è¯ï¼š" + ", ".join(VOCAB))
    st.stop()

# é¢„æµ‹
next_word, prototype, attn_weights, similarities = predict_next(tokens)

# ============================ å¯è§†åŒ– ============================
col1, col2 = st.columns(2)

with col1:
    # æ³¨æ„åŠ›çƒ­åŠ›å›¾
    fig_att = px.imshow(
        attn_weights.reshape(1, -1),
        labels=dict(x="å†å² token", y="", color="æ³¨æ„åŠ›æƒé‡"),
        x=tokens,
        text_auto=".2f",
        color_continuous_scale="Blues",
        aspect="auto"
    )
    fig_att.update_layout(title="1. æ³¨æ„åŠ›æƒé‡ï¼ˆå®ƒæ­£åœ¨å…³æ³¨å“ªé‡Œï¼‰", height=300)
    st.plotly_chart(fig_att, use_container_width=True)
    
    # ç›¸ä¼¼åº¦æ¡å½¢å›¾
    fig_bar = go.Figure(go.Bar(
        x=VOCAB,
        y=similarities,
        text=[f"{s:.2f}" for s in similarities],
        textposition="outside",
        marker_color="#FF6F61"
    ))
    fig_bar.update_layout(
        title=f"3. è¯æ±‡ç›¸ä¼¼åº¦ â†’ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼š<b style='color:#FF6F61'>{next_word}</b>",
        height=450,
        margin=dict(t=50, b=100)
    )
    st.plotly_chart(fig_bar, use_container_width=True)

with col2:
    # è¯­ä¹‰åŸå‹é›·è¾¾å›¾ï¼ˆå‰6ç»´ï¼‰
    semantic_labels = ["Greeting", "Question", "Self", "Farewell", "Punctuation", "Other"]
    fig_radar = go.Figure(data=go.Scatterpolar(
        r=prototype[:6],
        theta=semantic_labels,
        fill='toself',
        line_color="#636EFA"
    ))
    fig_radar.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[-0.5, 1.2])),
        title="2. è¯­ä¹‰åŸå‹ï¼ˆ6ä¸ªåŠ¨æ€è®¤çŸ¥ç»´åº¦ï¼‰",
        height=500
    )
    st.plotly_chart(fig_radar, use_container_width=True)

# ============================ ç»“æœå±•ç¤º ============================
st.success(f"é¢„æµ‹ç»“æœï¼š`{prompt}` â†’ **{next_word}** (seed={seed_proj})")
st.balloons()

# ============================ é¡µè„š ============================
st.markdown("---")
st.markdown("""
**è®ºæ–‡ä¸‹è½½**ï¼š[Dynamic Semantic Categorization Through Self-Referential Attention (PDF)](https://zenodo.org/records/17835987)  
**ä»£ç ä»“åº“**ï¼š[GitHub - wangzhongren/DynamicGPT](https://github.com/wangzhongren/DynamicGPT)  
""")
st.caption("â€œAI = Dynamic Categorizationâ€ â€” Zhongren Wang, 2025")